import requests
import socket
import whois
import urllib.parse
import re

# List of known phishing keywords in URLs
SUSPICIOUS_KEYWORDS = ["login", "bank", "paypal", "secure", "verify", "update", "account", "confirm"]

# List of public phishing blacklists
BLACKLIST_URLS = [
    "https://openphish.com/feed.txt",
    "https://raw.githubusercontent.com/mitchellkrogza/Phishing.Database/master/phishing-links/output/domains.txt"
]

# Expand Shortened URLs
def expand_short_url(url):
    try:
        response = requests.head(url, allow_redirects=True, timeout=5)
        return response.url
    except:
        return url

# Get Domain Information
def get_domain_info(url):
    try:
        domain = urllib.parse.urlparse(url).netloc
        ip_address = socket.gethostbyname(domain)
        domain_info = whois.whois(domain)
        return {
            "Domain": domain,
            "IP Address": ip_address,
            "Registrar": domain_info.registrar,
            "Creation Date": domain_info.creation_date,
            "Expiration Date": domain_info.expiration_date
        }
    except:
        return {"Error": "Unable to fetch domain details"}

# Check if URL is in Blacklists
def check_blacklist(url):
    domain = urllib.parse.urlparse(url).netloc
    for bl_url in BLACKLIST_URLS:
        try:
            response = requests.get(bl_url, timeout=5)
            if domain in response.text:
                return "âŒ UNSAFE: URL is Blacklisted!"
        except:
            pass
    return "âœ… SAFE: URL is not in Blacklists."

# Extract Hidden Links from the Page
def extract_links(url):
    try:
        response = requests.get(url, timeout=5)
        links = re.findall(r'href=[\'"]?([^\'" >]+)', response.text)
        return links[:5]  # Show first 5 links
    except:
        return ["âŒ Could not retrieve links."]

# Check for Suspicious Keywords
def check_suspicious_keywords(url):
    for keyword in SUSPICIOUS_KEYWORDS:
        if keyword in url.lower():
            return "âš ï¸ WARNING: URL contains suspicious words!"
    return "âœ… No suspicious words detected."

# Main Scanner Function
def scan_url():
    url = input("ğŸ”— Enter the URL to scan: ")

    print("\nğŸ” Expanding URL...")
    expanded_url = expand_short_url(url)
    print(f"âœ… Final URL: {expanded_url}")

    print("\nğŸŒ Checking Domain Information...")
    domain_info = get_domain_info(expanded_url)
    for key, value in domain_info.items():
        print(f"   {key}: {value}")

    print("\nğŸ›¡ï¸ Checking Blacklists...")
    blacklist_result = check_blacklist(expanded_url)
    print(blacklist_result)

    print("\nğŸ”— Extracting Hidden Links...")
    links = extract_links(expanded_url)
    for link in links:
        print(f"   â¤ {link}")

    print("\nğŸ” Checking for Suspicious Keywords...")
    keyword_result = check_suspicious_keywords(expanded_url)
    print(keyword_result)

    # Final Verdict
    print("\nğŸš€ Final Verdict:")
    if "UNSAFE" in blacklist_result or "WARNING" in keyword_result:
        print("âŒ This URL is **UNSAFE**! Do not visit.")
    else:
        print("âœ… This URL is **SAFE**!")

    print("\nâœ… Scan Completed!")

if __name__ == "__main__":
    scan_url()
